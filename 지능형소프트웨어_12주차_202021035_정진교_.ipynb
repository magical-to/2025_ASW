{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN880fO7JGqIX9QjCxxCg3J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magical-to/2025_ASW/blob/main/%EC%A7%80%EB%8A%A5%ED%98%95%EC%86%8C%ED%94%84%ED%8A%B8%EC%9B%A8%EC%96%B4_12%EC%A3%BC%EC%B0%A8_202021035_%EC%A0%95%EC%A7%84%EA%B5%90_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7RFduUmfhnV",
        "outputId": "260a6f81-39df-44cd-ba1e-b3d982293d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def chat_with_gpt(model, messages, temperature=1.0, max_tokens=None, seed=None):\n",
        "    max_retries = 3\n",
        "    retry_delay = 5\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=model,\n",
        "                messages=messages,\n",
        "                temperature=temperature,\n",
        "                max_tokens=max_tokens,\n",
        "                seed=seed\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "            print(f\"API error occurred: {e}\")\n",
        "            if attempt < max_retries - 1:\n",
        "                print(f\"Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "            else:\n",
        "                print(\"Max retries reached.\")\n",
        "                return None\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a knowledgeable assistant.\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Answer in Korean.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What are the health benefits of regular exercise?\"}\n",
        "]\n",
        "\n",
        "print(\"--- 기본 실행 ---\")\n",
        "result = chat_with_gpt(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "print(result)\n",
        "\n",
        "print(\"\\n--- max_tokens=200 ---\")\n",
        "result_short = chat_with_gpt(model=\"gpt-3.5-turbo\", messages=messages, max_tokens=200)\n",
        "print(result_short)\n",
        "\n",
        "print(\"\\n--- Temperature=0.1 (일관성) ---\")\n",
        "print(chat_with_gpt(model=\"gpt-3.5-turbo\", messages=messages, temperature=0.1))\n",
        "\n",
        "print(\"\\n--- Temperature=0.9 (창의성) ---\")\n",
        "print(chat_with_gpt(model=\"gpt-3.5-turbo\", messages=messages, temperature=0.9))\n",
        "\n",
        "print(\"\\n--- Seed=42 ---\")\n",
        "print(chat_with_gpt(model=\"gpt-3.5-turbo\", messages=messages, seed=42))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuyOCiOpgnnA",
        "outputId": "82000214-9600-4003-8d46-4ed260d8c379"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 기본 실행 ---\n",
            "규칙적인 운동은 건강에 많은 이점을 제공합니다. 일반적으로 운동을 하게 되면 신체적으로 더 강해지고 유연해지며 근력이 증가하게 됩니다. 또한 심혈관 기능을 향상시키고 체지방을 감소시켜 주며 대사 속도를 높여 신진대사를 촉진합니다. 정기적인 운동은 심리적으로도 이점을 가져다 줍니다. 스트레스를 줄여주고 우울증 증상을 완화시키며 자신감을 향상시키고 명료한 사고를 도와줍니다. 종합적으로 말하자면 꾸준한 운동은 건강한 신체와 정신 건강을 유지하는데 매우 중요합니다.\n",
            "\n",
            "--- max_tokens=200 ---\n",
            "정기적인 운동은 건강에 많은 이점을 제공합니다. 운동은 체중을 조절하고 심혈관 건강을 증진시키며 혈당 조절을 도와줍니다. 또한 운동은 우울증을 완화하고 스트레스를 감소시키며 잠을 향상시키는데 도움을 줄 수 있습니다. 더불어 운동은 근육 강화와 유연성 향상에도 도움을 줍니다. 종합적으로, 정기적인 운동은 건강한 삶을 유지하는데 중\n",
            "\n",
            "--- Temperature=0.1 (일관성) ---\n",
            "정기적인 운동은 건강에 많은 이점을 줍니다. 몇 가지 중요한 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동은 체중을 조절하고 유지하는 데 도움이 됩니다.\n",
            "2. 심혈관 건강: 운동은 심장 건강을 증진시키고 혈압을 낮추는 데 도움이 됩니다.\n",
            "3. 대사 활동 증진: 운동은 대사 활동을 증진시키고 혈당 조절에 도움을 줍니다.\n",
            "4. 강한 근육과 뼈: 운동은 근육과 뼈를 강화하여 골다공증과 같은 질병을 예방하는 데 도움이 됩니다.\n",
            "5. 스트레스 감소: 운동은 스트레스를 감소시키고 우울증을 완화하는 데 도움이 됩니다.\n",
            "\n",
            "이러한 이점들은 정기적인 운동을 통해 건강을 유지하고 질병을 예방하는 데 도움이 됩니다.\n",
            "\n",
            "--- Temperature=0.9 (창의성) ---\n",
            "정기적인 운동은 건강에 여러 가지 이점이 있습니다. 주요 이점은 다음과 같습니다:\n",
            "\n",
            "1. 체중 관리: 운동은 체중을 유지하거나 감량하는 데 도움을 줄 수 있습니다.\n",
            "2. 심혈관 건강: 운동은 심혈관 질환의 위험을 줄일 수 있고 혈압을 낮출 수 있습니다.\n",
            "3. 근력 강화: 규칙적인 운동은 근육을 강화하고 기능을 향상시킵니다.\n",
            "4. 스트레스 감소: 운동은 스트레스를 줄이고 우울감을 완화시킬 수 있습니다.\n",
            "5. 뼈 건강: 운동은 뼈 밀도를 증가시키고 골다공증의 위험을 줄일 수 있습니다.\n",
            "\n",
            "따라서 정기적인 운동을 통해 다양한 건강 이점을 누릴 수 있습니다.\n",
            "\n",
            "--- Seed=42 ---\n",
            "정기적인 운동은 건강에 많은 이점을 줍니다. 일정한 운동을 통해 신체적으로 강해지고 유연성이 향상되며 근육량이 증가합니다. 또한 운동은 심혈관 건강을 향상시키고 혈압을 낮추며 혈당 수치를 조절합니다. 정기적인 운동은 체지방을 감소시키고 대사를 촉진하여 체중을 관리하는 데 도움을 줍니다. 심리적으로도 운동은 스트레스를 감소시키고 우울증을 예방하며 자기 자신에 대한 자신감을 높여주는 효과가 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts, model=\"text-embedding-3-small\"):\n",
        "    texts = [text.replace(\"\\n\", \" \") for text in texts]\n",
        "    response = client.embeddings.create(input=texts, model=model)\n",
        "    return [data.embedding for data in response.data]\n",
        "\n",
        "color_words = [\"red\", \"blue\", \"yellow\", \"green\"]\n",
        "color_embeddings = get_embeddings(color_words)\n",
        "\n",
        "for word, embedding in zip(color_words, color_embeddings):\n",
        "    print(f\"{word}: {embedding[:5]}... (Length: {len(embedding)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdVMPswfgokh",
        "outputId": "dce8abc5-f9aa-44df-fae8-4bba630683eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "red: [-0.02211996167898178, -0.010933708399534225, -0.0028299882542341948, 0.019148845225572586, 0.01706906408071518]... (Length: 1536)\n",
            "blue: [-0.0011275681899860501, -0.016529185697436333, -0.013120132498443127, 0.014094147831201553, 0.005262590479105711]... (Length: 1536)\n",
            "yellow: [-0.014283397234976292, -0.018006160855293274, 0.027407361194491386, 0.057189468294382095, -0.010169499553740025]... (Length: 1536)\n",
            "green: [0.006280624307692051, -0.0011062989942729473, 0.0616002157330513, 0.015412422828376293, 0.002596053294837475]... (Length: 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# User will provide their own mydata.jsonl, so file creation is removed.\n",
        "\n",
        "# 4-2. 파일 업로드 (PDF 34p)\n",
        "file_response = client.files.create(\n",
        "    file=open(\"mydata.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        ")\n",
        "file_id = file_response.id\n",
        "print(f\"Uploaded File ID: {file_id}\")\n",
        "\n",
        "\n",
        "#ft_job = client.fine_tuning.jobs.create(\n",
        "#    training_file=file_id,\n",
        "#    model=\"gpt-3.5-turbo\"\n",
        "#)\n",
        "#print(f\"Fine-tune Job ID: {ft_job.id}\")\n",
        "\n",
        "print(\"\\n--- 파일 목록 ---\")\n",
        "print(client.files.list())\n",
        "\n",
        "client.files.delete(file_id)\n",
        "print(f\"\\nDeleted File ID: {file_id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-vJJCm1gr5h",
        "outputId": "e9823466-d2b9-4294-aa0a-97fb87a4c8a5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded File ID: file-Wg6hmSnmv1w85bJi2Q22zr\n",
            "\n",
            "--- 파일 목록 ---\n",
            "SyncCursorPage[FileObject](data=[FileObject(id='file-Wg6hmSnmv1w85bJi2Q22zr', bytes=3128, created_at=1764552994, filename='mydata.jsonl', object='file', purpose='fine-tune', status='processed', expires_at=None, status_details=None)], has_more=False, object='list', first_id='file-Wg6hmSnmv1w85bJi2Q22zr', last_id='file-Wg6hmSnmv1w85bJi2Q22zr')\n",
            "\n",
            "Deleted File ID: file-Wg6hmSnmv1w85bJi2Q22zr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_text(input_text, instruction):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that edits text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Please edit the following text: '{input_text}'. Instruction: {instruction}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "input_text = \"The quick brown fox jumps over the lazy dog.\"\n",
        "instruction = \"Change 'fox' to 'cat' and change the tense to past.\"\n",
        "\n",
        "edited_text = edit_text(input_text, instruction)\n",
        "print(f\"Original: {input_text}\")\n",
        "print(f\"Edited:   {edited_text}\")"
      ],
      "metadata": {
        "id": "1fMKp9CAgtQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(prompt):\n",
        "    try:\n",
        "        response = client.images.generate(\n",
        "            model=\"dall-e-3\",\n",
        "            prompt=prompt,\n",
        "            size=\"1024x1024\",\n",
        "            quality=\"standard\",\n",
        "            n=1,\n",
        "        )\n",
        "        return response.data[0].url\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "prompt = \"A futuristic cityscape at sunset, high quality, digital art\"\n",
        "image_url = generate_image(prompt)\n",
        "\n",
        "print(f\"Image URL: {image_url}\")\n",
        "from IPython.display import Image, display\n",
        "display(Image(url=image_url, width=500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "nzA0t-wJgwWz",
        "outputId": "4d677585-8d72-49e4-8c5c-1e9beba47535"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-OoaioKp0Ufgf9BfjHZ5nn3al/user-1Ky06u8pwuC2kAEmKfZyRi3V/img-zUrB4Iu7TQPC9bRlOAvkrl9C.png?st=2025-12-01T00%3A36%3A59Z&se=2025-12-01T02%3A36%3A59Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=0e2a3d55-e963-40c9-9c89-2a1aa28cb3ac&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-12-01T01%3A36%3A59Z&ske=2025-12-02T01%3A36%3A59Z&sks=b&skv=2024-08-04&sig=vlng0p9PpFh5Lpw9Vt9HaAJK0gIMy%2Bc6NRrZ2TL9Cwc%3D\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-OoaioKp0Ufgf9BfjHZ5nn3al/user-1Ky06u8pwuC2kAEmKfZyRi3V/img-zUrB4Iu7TQPC9bRlOAvkrl9C.png?st=2025-12-01T00%3A36%3A59Z&se=2025-12-01T02%3A36%3A59Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=0e2a3d55-e963-40c9-9c89-2a1aa28cb3ac&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-12-01T01%3A36%3A59Z&ske=2025-12-02T01%3A36%3A59Z&sks=b&skv=2024-08-04&sig=vlng0p9PpFh5Lpw9Vt9HaAJK0gIMy%2Bc6NRrZ2TL9Cwc%3D\" width=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code(prompt):\n",
        "    try:\n",
        "        response = client.completions.create(\n",
        "            model=\"gpt-3.5-turbo-instruct\",\n",
        "            prompt=prompt,\n",
        "            max_tokens=200,\n",
        "            temperature=0\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "prompt = \"Write a Python function that computes Fibonacci number using recursion.\"\n",
        "code = generate_code(prompt)\n",
        "\n",
        "print(\"Generated Code:\\n\")\n",
        "print(code)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYmBBDLwgyZ1",
        "outputId": "28e403d8-6340-4771-f2e0-268ec4b1b0e4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            "\n",
            "def fibonacci(n):\n",
            "    if n <= 1:\n",
            "        return n\n",
            "    else:\n",
            "        return fibonacci(n-1) + fibonacci(n-2)\n",
            "\n",
            "# Example:\n",
            "print(fibonacci(6)) # Output: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai gTTS\n",
        "\n",
        "from gtts import gTTS\n",
        "\n",
        "text = \"Deep in the darkness night, when there's a spark of hope.\"\n",
        "tts = gTTS(text)\n",
        "tts.save(\"test_audio.mp3\")\n",
        "\n",
        "def transcribe_audio(file_path):\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "        transcript = client.audio.transcriptions.create(\n",
        "            model=\"whisper-1\",\n",
        "            file=audio_file\n",
        "        )\n",
        "    return transcript.text\n",
        "\n",
        "result_text = transcribe_audio(\"test_audio.mp3\")\n",
        "print(f\"\\nTranscribed Text: {result_text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkp6ICkrg0C9",
        "outputId": "1c009d62-a791-49a1-c84e-8d6fe855ccae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.12/dist-packages (2.5.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from gTTS) (2.32.4)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.12/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->gTTS) (2.5.0)\n",
            "\n",
            "Transcribed Text: Deep in the darkness night, when there's a spark of hope.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Dracula.mp3'\n",
        "\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcription Response : \")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gaTJUZEkMzs",
        "outputId": "d94cc6cb-7e16-4fb4-f967-178113e81ff9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription Response : \n",
            "Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse. The candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders searching for some precious grail. We are the embers that glow in the winter. The diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses, he will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds.\n"
          ]
        }
      ]
    }
  ]
}